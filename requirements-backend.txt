# Backend-only requirements for inference
# Minimal dependencies for running the prediction service
#
# Install with:
#   pip install torch --index-url https://download.pytorch.org/whl/cpu
#   pip install -r requirements-backend.txt
#
# Or for GPU support:
#   pip install torch
#   pip install -r requirements-backend.txt

# ============================================================
# Core ML
# ============================================================
# PyTorch - install separately with CPU or GPU wheel
# torch>=2.0.0

numpy>=1.24.0,<2.0
pandas>=2.0.0
scikit-learn>=1.3.0
joblib>=1.3.0

# ============================================================
# API / HTTP
# ============================================================
requests>=2.31.0
fastapi>=0.104.0
uvicorn>=0.24.0

# ============================================================
# Scheduling (for hourly runs)
# ============================================================
schedule>=1.2.0

# ============================================================
# Optional: APScheduler for more robust scheduling
# ============================================================
# APScheduler>=3.10.0
